# 时间复杂度

运行时间可以直观且准确地反映算法的效率。如果我们想准确预估一段代码的运行时间，应该如何操作呢？

1. **确定运行平台**，包括硬件配置、编程语言、系统环境等，这些因素都会影响代码的运行效率。
2. **评估各种计算操作所需的运行时间**，例如加法操作 + 需要 1 ns ，乘法操作 * 需要 10 ns ，打印操作 print() 需要 5 ns 等。
3. **统计代码中所有的计算操作**，并将所有操作的执行时间求和，从而得到运行时间。
例如在以下代码中，输入数据大小为n:
```java
// 在某运行平台下
void algorithm(int n) {
    int a = 2;  // 1 ns
    a = a + 1;  // 1 ns
    a = a * 2;  // 10 ns
    // 循环 n 次
    for (int i = 0; i < n; i++) {  // 1 ns
        System.out.println(0);     // 5 ns
    }
}
```
根据以上方法，可以得到算法的运行时间为(6n+12)ns ：
```
1+1+10+(1+5)*n = 6n+12
```

但实际上，**统计算法的运行时间既不合理也不现实**。首先，我们不希望将预估时间和运行平台绑定，因为算法需要在各种不同的平台上运行。其次，我们很难获知每种操作的运行时间，这给预估过程带来了极大的难度。

## 01 统计时间增长趋势
时间复杂度分析统计的不是算法运行时间，**而是算法运行时间随着数据量变大时的增长趋势**。
“时间增长趋势”这个概念比较抽象，我们通过一个例子来加以理解。假设输入数据大小为n ，给定三个算法 A、B 和 C ：
```java
// 算法 A 的时间复杂度：常数阶
void algorithm_A(int n) {
    System.out.println(0);
}
// 算法 B 的时间复杂度：线性阶
void algorithm_B(int n) {
    for (int i = 0; i < n; i++) {
        System.out.println(0);
    }
}
// 算法 C 的时间复杂度：常数阶
void algorithm_C(int n) {
    for (int i = 0; i < 1000000; i++) {
        System.out.println(0);
    }
}
```

图 2-7 展示了以上三个算法函数的时间复杂度。

- 算法 A 只有1个打印操作，算法运行时间不随着n增大而增长。我们称此算法的时间复杂度为“常数阶”。
- 算法 B 中的打印操作需要循环n次，算法运行时间随着n增大呈线性增长。此算法的时间复杂度被称为“线性阶”。
- 算法 C 中的打印操作需要循环1000000次，虽然运行时间很长，但它与输入数据大小n无关。因此 C 的时间复杂度和 A 相同，仍为“常数阶”。
![](https://raw.githubusercontent.com/cheng000/picture/main/vitepress-blog/20240925124707.png)
<div align="center">图 2-7   算法 A、B 和 C 的时间增长趋</div>

相较于直接统计算法的运行时间，时间复杂度分析有哪些特点呢？

- **时间复杂度能够有效评估算法效率。** 例如，算法 B 的运行时间呈线性增长，在n>1时比算法 A 更慢，在n>1000000时比算法 C 更慢。事实上，只要输入数据大小n足够大，复杂度为“常数阶”的算法一定优于“线性阶”的算法，这正是时间增长趋势的含义。
- **时间复杂度的推算方法更简便。** 显然，运行平台和计算操作类型都与算法运行时间的增长趋势无关。因此在时间复杂度分析中，我们可以简单地将所有计算操作的执行时间视为相同的“单位时间”，从而将“计算操作运行时间统计”简化为“计算操作数量统计”，这样一来估算难度就大大降低了。
- **时间复杂度也存在一定的局限性。** 例如，尽管算法 A 和 C 的时间复杂度相同，但实际运行时间差别很大。同样，尽管算法 B 的时间复杂度比 C 高，但在输入数据大小n较小时，算法 B 明显优于算法 C 。对于此类情况，我们时常难以仅凭时间复杂度判断算法效率的高低。当然，尽管存在上述问题，复杂度分析仍然是评判算法效率最有效且常用的方法。

## 02 函数渐近上界
给定一个输入大小为n的函数：
```java
void algorithm(int n) {
    int a = 1;  // +1
    a = a + 1;  // +1
    a = a * 2;  // +1
    // 循环 n 次
    for (int i = 0; i < n; i++) { // +1（每轮都执行 i ++）
        System.out.println(0);    // +1
    }
}
```
设算法的操作数量是一个关于输入数据大小n的函数，记为T(n)，则以上函数的操作数量为：
```
T(n) = 3+2n
```
T(n)是一次函数，说明其运行时间的增长趋势是线性的，因此它的时间复杂度是线性阶。
我们将线性阶的时间复杂度记为O(n)，这个数学符号称为大O记号（big-O-notation），表示函数T(n)的渐近上界（asymptotic upper bound）。
时间复杂度分析本质上是计算“操作数量T(n)”的渐近上界，它具有明确的数学定义。

::: tip  函数渐近上界
若存在正实数c和实数n0，使得对于所有的n>n0，均有T(n)≤c*f(n)，则可认为f(n)给出了T(n)的一个渐近上界，记为T(n) = O(f(n))。
:::

如图 2-8 所示，计算渐近上界就是寻找一个函数f(n)，使得当n趋向于无穷大时，T(n)和f(n) 处于相同的增长级别，仅相差一个常数项c的倍数。
![](https://raw.githubusercontent.com/cheng000/picture/main/vitepress-blog/20240925125550.png)
<div align="center">图 2-8   函数的渐近上界</div>


## 03 推算方法
渐近上界的数学味儿有点重，如果你感觉没有完全理解，也无须担心。我们可以先掌握推算方法，在不断的实践中，就可以逐渐领悟其数学意义。
根据定义，确定f(n)之后，我们便可得到时间复杂度O(f(n))。那么如何确定渐近上界f(n)呢？总体分为两步：首先统计操作数量，然后判断渐近上界。

### 01 第一步：统计操作数量
针对代码，逐行从上到下计算即可。然而，由于上述c*f(n)中的常数项 c可以取任意大小，**因此操作数量T(n)中的各种系数、常数项都可以忽略**。根据此原则，可以总结出以下计数简化技巧。
1. **忽略T(n)中的常数项**。因为它们都与n无关，所以对时间复杂度不产生影响。
2. **省略所有系数**。例如，循环2n次、5n+1次等，都可以简化记为n次，因为n前面的系数对时间复杂度没有影响。
3. **循环嵌套时使用乘法**。总操作数量等于外层循环和内层循环操作数量之积，每一层循环依然可以分别套用第 1. 点和第 2. 点的技巧。

给定一个函数，我们可以用上述技巧来统计操作数量：
```java
void algorithm(int n) {
    int a = 1;  // +0（技巧 1）
    a = a + n;  // +0（技巧 1）
    // +n（技巧 2）
    for (int i = 0; i < 5 * n + 1; i++) {
        System.out.println(0);
    }
    // +n*n（技巧 3）
    for (int i = 0; i < 2 * n; i++) {
        for (int j = 0; j < n + 1; j++) {
            System.out.println(0);
        }
    }
}
```
![](https://raw.githubusercontent.com/cheng000/picture/main/vitepress-blog/20240925130100.png)

### 02 第二步：判断渐近上界